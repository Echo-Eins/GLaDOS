import torch
import gigaam

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
AUDIO_PATH = r"C:\Users\Lenovo\Downloads\ex4.wav"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE.upper()}")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π ===
print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ GigaAM...")
asr_model = gigaam.load_model("rnnt")
emo_model = gigaam.load_model("emo")

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞—ë–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
asr_model.device = DEVICE
emo_model.device = DEVICE

# === –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Ä–µ—á–∏ ===
print("‚Üí –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å...")
text = asr_model.transcribe(AUDIO_PATH)
print(f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {text}")

# === –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π ===
print("‚Üí –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–º–æ—Ü–∏—é...")
emotions = {k: round(float(v), 4) for k, v in emo_model.get_probs(AUDIO_PATH).items()}
dominant = max(emotions, key=emotions.get)

print("üé≠ –≠–º–æ—Ü–∏–∏:")
for emo, val in emotions.items():
    print(f"  {emo:<8}: {val:.4f}")
print(f"‚û°Ô∏è –û—Å–Ω–æ–≤–Ω–∞—è —ç–º–æ—Ü–∏—è: {dominant}")

result = {"text": text, "emotion": dominant, "emotions": emotions}

print("\nüì¶ –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:")
print(result)
